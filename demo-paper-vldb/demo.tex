\documentclass{vldb}
\usepackage{pgfplots}
\usepackage{amssymb}
\usepackage{url}
\usepackage{enumitem}
\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage[export]{adjustbox}
\usepackage{xspace}
\usepackage{breqn}

\newtheorem{example}{Example}
\newtheorem{problem}{Problem}
\newtheorem{definition}{Definition}

\newcommand{\framework}{{\sc GeoGuide}}
\newcommand{\pb}{{\sc GeoGuide}}

\title{An Interactive Guidance Approach for Spatial Data}

\author{
Behrooz Omidvar-Tehrani$^{\dag}$, Pl\'acido A. Souza Neto$^{\ddag}$\\
\affaddr{
$^{\dag}$The Ohio State University, USA, $^{\ddag}$Federal Institute of Rio Grande do Norte - IFRN, Brazil}\\
\affaddr{
$^{\dag}$\path{omidvar-tehrani.1@osu.edu},
$^{\ddag}$\path{placido.neto@ifrn.edu.br}
}}

\date{}

\begin{document}
\maketitle

\begin{abstract}
Spatial data is becoming increasingly available in various domains such as urban management and social science. Discovering patterns and trends in this data provides improved insights for planning and decision making in several applications such smart city and disaster management. However, exploratory analysis of such data is a challenge due to its huge size of spatial data. It is often unclear for the analyst {\em what to see next} during an analysis process, i.e., lack of guidance. To tackle this challenge, we develop \framework, an interactive guidance approach for spatial data. \framework\ captures the feedback of analysts and exploits it to highlight potentially interesting analysis options. Demonstration attendees experience the web-based implementation of \framework\ in various scenarios.
 %Demo attendees will experience \framework\ in various datasets from restaurant check-ins to transportation. 
\end{abstract}

\section{Introduction} 
Nowadays, there exists huge amounts of spatial data in various fields of science, such as agriculture, transportation and social science. Analysis of such data is interesting as it is grounded
on reality: each record represents a specific geographical location. Moreover, understanding patterns and trends provides insights leading to improved user planning and decision making. Some instance applications of spatial data are smart city management, disaster management and autonomous transport.
% \cite{RoddickEHPS04,Telang:2012}.


Spatial data analysis is often performed in {\em exploratory context}: the analyst does not have a precise query in mind and she explores data in iterative steps in order to find potentially interesting results. Traditionally, an exploratory analysis scenario on spatial data is described as follows: the analyst visualizes a subset of data using a query in an off-the-shelf product (e.g., Tableau\footnote{\it http://www.tableau.com},
% Exhibit\footnote{\it http://www.simile-widgets.org/exhibit/},
Spotfire\footnote{\it http://spotfire.tibco.com}). %The result will be illustrated on a geographical map. Then she investigates on different parts of the visualization by zooming in/out and panning the map in order to discover patterns and trends of interest. The analyst may iterate on this process several times by issuing different queries and focusing on different aspects of data. 


The literature in spatial data analysis has a focus on {\em efficiency} of exploratory iterations: {\em ``how can analysts navigate in spatial data fluidly?''} The common approach is to design pre-computed indexes which enable efficient retrieval of spatial data (e.g., \cite{lins2013nanocubes}). However, there has been fewer attention to the {\em value} of spatial data. Despite the huge progress on efficiency front, an analyst may easily get lost in the plethora of geographical points because $i.$ she doesn't know what to investigate next in an exploratory context and $ii.$ she may get distracted and miss interesting points by visual clutter caused by huge point overlaps. In other words, although iteration transitions (between one analysis step to the other) can be performed efficiently, the decision which forms a transition, remains unclear.



There exist few instances of information-highlighting methods in the literature \cite{Liang2010,Robinson2011,wongsuphasawat2016voyager,willett2007scented}. All these methods are {\em objective} and do not apply to the context of spatial guidance where user feedback is involved.  In terms of recommendation, few approaches focus on spatial dimension \cite{Bao2015,Levandoski:2012} while the context and result diversification are missing.
 

%The following example illustrates the challenge in practice.

%\begin{example}
%\label{ex:airbnb}
%Liam is planning a short trip to Paris. He decides to rent a home-stay from Airbnb website\footnote{\it http://www.airbnb.com}. He is open to any type of lodging and he wants to explore different options (i.e., exploratory analysis). He queries all available locations in Paris with a fair price. His query results in 3000 locations. As he has no other preferences, an exhaustive investigation needs scanning each location independently which is nearly infeasible. In case he wants to focus on a smaller set of options, it is not clear which subset he needs to look at. While he is looking at primary locations in the list, he shows interest in having ``balcony'' as amenity and being close to Eiffel tower. An ideal system can capture this feedback in order to short-list a small subset of remaining locations that Liam should consider as high priority.
%\end{example}

To overcome the challenge of value in exploratory analysis, visualization environments offer a complete tool-set to manipulate data (filter, aggregate, etc.). In practice, this duplicates the problem: the analyst is left alone in a huge space of spatial data and tools. The principled challenge for the analyst is {\em ``what to see next''} in the exploratory context. A {\em guidance} mechanism is then necessary to point out potential future directions of analysis.

\vspace{5pt}
\noindent{\bf Contribution.} We demonstrate \framework, an interactive framework to highlight a subset of geographical points based on analyst feedback. Although \framework\ operates on points, its functionality can be easily extended to regions using point-clustering methods. The highlighted set facilitates the decision-making process by providing guidance on what the analyst should potentially concentrate on. The set of highlights is deliberated over high quality. We consider two quality metrics in \framework: {\em relevance} and {\em diversity}. First, each highlighted point should be relevant to historical choices of the analyst. Second, highlights should be geographically diverse to unveil different aspects of analysis. Both quality metrics are interdependent to compute the set of highlights.

Despite literature contains several instances of feedback exploitation to guide the analyst in further analysis steps (e.g., \cite{boley2013one}), the common used approach is the top-$k$ processing methodology in order to prune the search space based on the explicit feedback and recommend a small subset of interesting results of size~$k$. A clear distinction and contribution of \framework\ is that it doesn't aim for pruning, but leveraging the actual data with potential interesting results that the analyst may miss due to the huge volume of spatial data. While in top-$k$ processing algorithms, analyst choices are limited to $k$, \framework\ has a freedom of choice where highlights get seamlessly updated with new analyst choices. We present a system overview in
Section \ref{sec:pb} and our demonstration plan in Section \ref{sec:demo_plan}. 



%The following example describes an application of \framework\ in business domain.

%\begin{example}
%\label{ex:flight}
%Tiffany is a data scientist and is tasked to design a ``chain marketing'' strategy for a Peking Duck product (a Chinese duck dish). She decides to exploit Yelp data\footnote{\it https://www.yelp.com/} (i.e., restaurant check-ins) to find out the advertisement chain. She performs her analysis in \framework. In the first step, she shows interest towards New York region, where the headquarters of the company is located and the product has already gained success. The system will then provide few highlights in diverse regions: San Fransisco, Washington DC and Marlton, NJ. All regions seem interesting to Tiffany as they exhibit similar eating profile with New York, hence potentials for chaining the advertisement. She decides to pick Marlton due to its proximity so that she can reduce transportation costs. The system will then provide other highlights based on her updated feedback. She can then make the city-to-city chain marketing strategy in iterative steps using highlights.
%\end{example}


\section{System Overview}
\label{sec:pb}

Given a dataset with a set of spatio-temporal information points, our system is able to process and generates highlighted informations base on analyst preferences and behaviour. Our proposed framework is able to highlight different information based on specific data attributes, highlighting, for instance, each points by size or color intensity. Using \framework\ framework the analyst can also define a subset of points to be highlighted over the dataset by a simple filtering action. The functionalities of \framework\ are an inspiration from both recommendation \cite{Omidvar-Tehrani:2015} and visual highlighting \cite{Liang2010,Robinson2011} methodologies. \framework\ is a layer on top of a raw visualization to guide analysts in large-scale spatial data analysis. Figure \ref{fig:framework} illustrates the main components of \framework\ architecture.


\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figs/framework}
\caption{\framework\ Framework}
\label{fig:framework}
\vspace{-10pt}
\end{figure}

The following example illustrates the challenge of our approach in practice.

\begin{example}
\label{ex:airbnb}
Liam is planning a short trip to Paris. He decides to rent a home-stay from Airbnb website\footnote{\it http://www.airbnb.com}. He is open to any type of lodging and he wants to explore different options (i.e., exploratory analysis). He queries all available locations in Paris with a fair price. His query results in 3000 locations. As he has no other preferences, an exhaustive investigation needs scanning each location independently which is nearly infeasible. In case he wants to focus on a smaller set of options, it is not clear which subset he needs to look at. While he is looking at primary locations in the list, he shows interest in having ``balcony'' as amenity and being close to Eiffel tower. An ideal system can capture this feedback in order to short-list a small subset of remaining locations that Liam should consider as high priority.
\end{example}

In our framework, we consider a spatial database ${\cal D}$ consisting $\langle {\cal P}, {\cal A} \rangle$ where ${\cal P}$ is the set of
geographical points and ${\cal A}$ is the set of point attributes. For each $p \in {\cal P}$, we consider a tuple $\langle lat, lon, alt\rangle$ which denotes $p$'s geographical coordinates (latitude, longitude and altitude respectively). The set ${\cal A}_p$ contains attribute-values for $p$ over the schema of ${\cal A}$. For instance, on a bike-sharing dataset, ${\cal A}_p = \langle${\tt female}, {\tt young}, {\tt hybrid-bike}$\rangle$ on the schema ${\cal A} = \langle${\tt gender}, {\tt age}, {\tt type}$\rangle$ denotes that $p$ is associated to a young female cyclist who rides a hybrid bike. The set ${\cal A}$ is domain-dependent and defines the semantics of a spatial dataset.

We also define a feedback vector ${\cal F}$ on the schema ${\cal A}$ initialized by zero. The vector gets updated by ${\cal A}_p$ whenever the analyst shows interest in a geographical point $p$. Feedback vector is always kept normalized, i.e., $\Sigma_{v \in {\cal F}}(v) = 1.0$. Unlike the literature which mainly focuses on explicit feedback (where the analyst should clearly reflect her likes and dislikes), we investigate on implicit feedback. This enables the system to capture {\em what the analyst may miss} instead of what the analyst has clearly investigated before. We consider different ways to capture implicit feedback.

\begin{itemize}[leftmargin=*]
\item {\bf Gaze Tracking.} During spatial data analysis, it is often the case that analysts look at some regions of interest but forget to provide an explicit feedback. For instance in Example~\ref{ex:airbnb}, while Liam is focusing on home-stays close to the Eiffel tower, he also looks at farther locations with easy train access. However, he never clicks on those points. We call this latent signal, {\em gaze}. It shown in \cite{fischer1999investigation} that gaze has a strong correlation with ``user attention''. The signal can be captured by tracking eye movements aka saccades~\cite{arapakis2014user}. We employ {\sc ixLabs} gaze tracking\footnote{\em http://www.xlabsgaze.com/} as it only needs a simple web-cam to capture the gaze signal.
\item {\bf Cursor Tracking.} To address privacy issues of web-cam exploitation for gaze tracking, we consider an alternative option of tracking the mouse cursor. It is shown in \cite{arapakis2014understanding} that mouse gestures have a strong correlation with ``user engagement''. Intuitively, a point receives a positive feedback if the cursor moves around it frequently.
\item {\bf Session Time.} In most spatial datasets, there is a profile page dedicated to each point. Examples are restaurant pages in Yelp and lodging pages in Airbnb. We consider the amount of time that the analyst spends in a page as an implicit feedback. For instance, if the analyst spends few minutes in a page for an Indian cuisine restaurant, this counts as positive feedback for this type of restaurants. 
\end{itemize}

At each step of the analysis, \framework\ highlights few points based on the feedback content ${\cal F}$. The highlighting decision is made based on two quality metrics, i.e., relevance and diversity. 

\vspace{5pt}
\noindent {\bf Relevance.} Highlights should be in the same line with analyst feedback (captured either by gaze, mouse cursor or session time). Note that we consider {\em contextual-based} relevance and not {\em distance-based} relevance. The reason originates from our data observation. For instance in a taxi dataset, consider a ride in New York for a young male customer for an itinerary of 10 kilometers and \$3 tip. In contrary to thousands of kilometers of geographical distance, the ride is very relevant to another one in San Fransisco for a middle-age male customer for an itinerary of 8 kilometers and \$2.5 tip. The relevance between a point $p$ and the feedback vector ${\cal F}$ is defined as follows.

% \begin{definition}[Relevance]
% Given two points $p$ and $p'$ and their attribute values ${\cal A}_{p}$ and ${\cal A}_{p'}$, the relevance between $p$ and $p'$ is a value between $0$ and $1$ denoted as $\mathit{relevance}(p,p') = \mathit{average}_{a \in {\cal A}_{p} \cup {\cal A}_{p'}}(\mathit{sim({\cal A}_{p}, {\cal A}_{p'}, a)})$.
% \label{def:rel}
% \end{definition}

\begin{dmath}
\label{eq:rel}
\mathit{relevance}(p,{\cal F}) = \mathit{average}_{a \in {\cal A}_{p} \cap {\cal F}}(\mathit{sim(p, {\cal F}, a)})
\end{dmath}

The similarity function $\mathit{sim}()$ can be any function such as Jaccard and Cosine. Each attribute can have its own similarity function (as string and integer attributes are compared differently.) Then $\mathit{sim}()$ works as an overriding-function which provides encapsulated similarity computations for any type of attribute.

\vspace{5pt}
\noindent {\bf Diversity.} Highlighted points should also represent distinct regions so that the analyst can observe different aspects of data and decide based on the big picture. Given a set of points $s = \{ p_1, p_2 \dots \}$, we define {\em diversity} as follows.

\begin{dmath}
\label{eq:divs}
\mathit{diversity}(s) = \mathit{average}_{\{p, p'\} \subseteq s | p \neq p' } \mathit{distance}(p,p')
\end{dmath} 

The function $\mathit{distance}(p,p')$ operates on geographical coordinates of $p$ and $p'$ and can be considered as any distance function of Chebyshev distance family such as Eucledian. However, as distance computations are done in {\em spherical space} using latitude, longitude and altitude, it is au-naturel to employ Haversine distance shown in Equation \ref{eq:harvestine}.

\begin{dmath}
\label{eq:harvestine}
distance(p,p') = [ acos(cos(p_{lat}) . cos(p'_{lat}) . cos(p_{lon}) . cos(p'_{lon})\\ + cos(p_{lat}) . sin(p'_{lat}). cos(p_{lon}) . sin(p'_{lon}) + sin(p_{lat}) . sin(p'_{lat})) ] \times earth\_radius
\end{dmath}

% \vspace{5pt}
% Following aforementioned desiderata, we formulate highlighting as an optimization-based problem on relevance and diversity dimensions.

% \begin{problem}[\pb]
% \label{pb:geoh}
% Given an input point $p$ and a threshold $\sigma$, the problem is to return top-$k$
%  points denoted $S_p$ where $|S_p| = k$ and $\forall p' \in S_p, \mathit{relevance}(p,p') \geq \sigma$ and $\mathit{diversity}(S_p)$ is maximized.
% \end{problem}

% Problem \ref{pb:geoh} is hard due to the huge space of spatiotemporal data: for any given point $p$, an exhaustive search over all other points is necessary to find $k$ points with maximal relevance. Moreover, the problem investigates in two dimensions at the same time (relevance and diversity) which makes it more challenging.

\framework\ employs a best-effort greedy approach to efficiently compute highlighted points. We consider an offline step followed by the online execution of \framework.
In order to speed up computing relevance in online execution, we pre-compute an inverted index for each single geographical point in ${\cal P}$ in the offline step (as is commonly done in Web search). Each index ${\cal L}_p$ for the point $p$ keeps all other points in ${\cal P}$ in decreasing order of their relevance with $p$.

During online execution, \framework\ admits as input a point $p \in {\cal P}$ (the user explicit choice) and returns the set of highlights ${\cal H} \subset {\cal P}$. \framework\ makes sequential accesses to ${\cal L}_p$ to greedily maximize diversity. Points in ${\cal L}_p$ get a weight using ${\cal F}$. Points with a larger weight (i.e., closer to the analyst feedback) have a higher chance to be in ${\cal H}$. To speed up comparisons with ${\cal F}$ vector, we exploit bit-wise comparisons. We convert both ${\cal F}$ and point $p$ to boolean representations and compute relevance (Equation \ref{eq:rel}) using bit-wise operators.

\framework\ does not sacrifice efficiency in price of value. We consider a {\em time limit} parameter which determines when the algorithm should stop seeking maximized diversity. Scanning inverted indexes guarantees the relevance even if time limit is chosen to be very restrictive. Our observations with several datasets show that we achieve the diversity of more than $0.9$ with time limit set to $200ms$.

% The point-feedback relevance is neither monotonic nor anti-monotonic. In other words, a highly relevant point to the feedback vector at step $i$ may become totally irrelevant to the updated feedback vector at step $i+1$. The reason is the dynamic nature of the feedback vector which may drastically evolve at each analysis step. For efficiency reasons, we employ a static component of relevance and build indexes to speed up online computations.

%\noindent{\bf Context.} 
\framework\ is implemented in Python (as the computation engine) and JavaScript D3 (as the visualization engine). Demonstration attendees can play the role of analysts in \framework. We provide several spatial datasets in our demo session: Yelp dataset of restaurant check-ins with 229,907 geographical points, Airbnb dataset for short-term lodging with 4,200,000 points, New York taxi dataset with 173,179,759 points. Participants can also experience different types of feedback capturing such as gaze, mouse movement and session time. We describe three demonstration scenarios as follows.

% and New York bike-sharing dataset with XXX points.
\section{Demonstration Plan}
\label{sec:demo_plan}

Our demonstration plan consists of 5 parts. First,
we would like to present to the VLDB attendees the diversity of
parameters in three different scenarios and its datasets. Second, we will demonstrate the how to set the \framework\ variables before start the analysis by choosing a specific point in the map. Third, the attendees will be able to effectively see the highlighted points generated by the environment, and its properties. Fourth, we will present how to align different filter types in order to improve the results. Fifth, we will present to the attendees the use of implicit and explicit feedbacks, e.g., (i) how we capture cursor tracking in order to capture implicit informations (ii) by explicit choosing different parameters to be highlighted in therms of size and colors.



\vspace{5pt}
\noindent{\it Scenario 1.} On New York taxi dataset, we demonstrate how \framework\ can contribute to urban planning and fleet management. We consider an explicit goal of discovering which neighborhoods work the best for which drivers in order to increase the overall availability of cabs in the city. We show how a chain of cab stations can be picked by \framework\ in diverse location of the city.

\vspace{5pt}
\noindent{\it Scenario 2.} On Airbnb dataset, we demonstrate how \framework\ can contribute to approach a lodging of interest based on analyst's feedback. As instructed in the user study, we consider the concrete case of finding a cheap lodging solution with a balcony near Eiffel tower. The attendee will observe how feedback converges the exploration towards the goal very quickly.

\vspace{5pt}
\noindent{\it Scenario 3.} On Yelp dataset, e demonstrate how \framework\ can contribute to reach an early consensus on a restaurant. The attendee will observe that his/her preferences will be immediately captured and reflected in future highlights. The attendee can experience session time feedback in this scenario.


\begin{figure*}[!ht]
  \centering
  \includegraphics[width=\columnwidth]{figs/scn}
\caption{\framework\ on New York Taxi Dataset}
\label{fig:app}
% \vspace{-10pt}
\end{figure*}

\vspace{5pt}
\noindent{\bf 1. Diversity of parameters in three different datasets. }

\vspace{5pt}
\noindent{\bf 2. Setting framework variables. }

\vspace{5pt}
\noindent{\bf 3. Highlighted points generated by the system. }

\vspace{5pt}
\noindent{\bf 4. Filtering different properties. }

\vspace{5pt}
\noindent{\bf 5. Implicit and explicit feedbacks. }

\vspace{5pt}
To validate our design choices in \framework\ (quality dimensions and feedback capturing), we design a user study with $24$ participants (students in Computer Science). We define a task for each participant and ask him/her to fulfill the task using \framework\ and {\sc Tableau} (as the most advanced off-the-shelf visualization product). Then we measure the number of steps to reach the goal. We define two tasks, {\em T1: finding a point in a requested location} (e.g., find a home-stay in the Central Park area, New York), and {\em T2: finding a point with a requested profile} (e.g., find a cheap home-stay with balcony in Paris.) Participants may begin their navigation from three different starting points: {\em I1: close to the goal}, {\em I2: far from the goal}, and {\em I3: random}. 

In {\sc Tableau}, participants employ filtering and querying tools to reach their goals. In \framework, participants benefit from relevant and diverse highlights and feedback capturing using cursor tracking. Figure \ref{fig:userstudy} illustrates the results of this study. We report results for separate sub-populations: the left figure illustrates the results for novice participants (who don't know the location, be it Paris or New York) and the right figure illustrates expert's results.

We observe that in general, it takes in average 10.7 steps to reach a defined goal in \framework, i.e., 33 steps less than {\sc Tableau}. This shows that the highlighting component equipped with the feedback mechanism helps analysts discover their spatial data and reach to the goal. Level of expertise improves the analysis length in average by 4 steps. Interestingly, starting points do not have a huge influence. It is potentially due to the diversity component which provides distinct options. We also observe that {\em T2} is an easier task than {\em T1}. This is potentially due to similarity component where the analyst can request options similar to what she has already seen and greedily moves to match profiles.

\begin{figure}[t]
 \centering
 \includegraphics[width=\columnwidth]{figs/userstudy}
\caption{User Study}
\vspace{-5pt}
\label{fig:userstudy}
\end{figure}




\bibliographystyle{abbrv}
\bibliography{main}

\end{document}
 
